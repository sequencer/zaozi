# RVProbe Agent Configuration
# ============================

# ── Agent ────────────────────────────────────────────────────────────────────
agent:
  # LLM (model name is read from LLM_MODEL in .env; API key/base from LLM_API_KEY/LLM_API_BASE)
  llm_temperature: 0.0      # 0.0 for reproducibility, higher for creativity
  llm_max_tokens: 4000      # Maximum tokens per LLM response
  max_retries: 3            # Max auto-retry attempts on compile/SMT failure
  timeout_seconds: 60       # Timeout for Mill execution (seconds)

# ── XiangShan Difftest ───────────────────────────────────────────────────────
difftest:
  # Paths
  test_bin:        "/home/clo91eaf/Project/zaozi/out/test.bin"
  nexus_am_home:   "/home/clo91eaf/Project/xs-env/nexus-am"
  nexus_am_test_dir: "/home/clo91eaf/Project/xs-env/nexus-am/tests/rvprobetest"
  nexus_am_arch:   "riscv64-xs"
  workload_bin:    "build/rvprobetest-riscv64-xs.bin"   # relative to nexus_am_test_dir
  emu_bin:         "/home/clo91eaf/Project/xs-env/XiangShan/build/emu"
  diff_so:         "/home/clo91eaf/Project/xs-env/XiangShan/ready-to-run/riscv64-nemu-interpreter-so"
  # nix develop flake dir used to wrap the make command (empty string = run make directly)
  nix_develop_dir: "/home/clo91eaf/Project/xs-env"
  # Emulator log file
  emu_log:         "/tmp/xs_difftest.log"

# ── Benchmark ────────────────────────────────────────────────────────────────
benchmark:
  # Test selection (leave empty to run all)
  selected_tests: []      # e.g. ["TC-S01", "TC-S02"]
  difficulty_filter: []   # e.g. ["simple", "medium"]  (empty = all)

  # Parallel execution
  parallel_execution: false
  max_workers: 4

  # Statistical validity
  num_repetitions: 1      # Increase to 3 for statistical analysis

  # Cost tracking (USD per 1M tokens)
  prompt_token_cost: 0.0025     # $2.50 / 1M input tokens
  completion_token_cost: 0.010  # $10.00 / 1M output tokens

  # Methods
  method_a:
    enabled: true
    name: "Full Agent"
    description: "RAG + LLM + DSL + Mill + Z3 + Auto-retry"

  method_b:
    enabled: true
    name: "Direct LLM"
    variants:
      - id: "no_docs"
        description: "Pure LLM without documentation"
        include_documentation: false
      - id: "with_docs"
        description: "LLM with constraint documentation"
        include_documentation: true

# ── Output ───────────────────────────────────────────────────────────────────
output:
  results_dir: "./benchmark_results"
  save_raw_outputs: true        # Save full LLM outputs for debugging
  log_level: "INFO"             # DEBUG | INFO | WARNING | ERROR
  log_file: "./benchmark_results/benchmark.log"
  console_output: true

  visualization:
    enabled: true
    output_format: "png"        # png | svg | pdf
    dpi: 300
    figure_size: [10, 6]
    style: "seaborn-v0_8-darkgrid"

  report:
    enabled: true
    format: "markdown"          # markdown | html
    output_file: "./benchmark_results/REPORT.md"
    include_detailed_analysis: true
    include_failure_analysis: true
    include_recommendations: true
